{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nmf_model import NMFModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(\"../datasets/assignment/train_set.csv\")\n",
    "test_data=pd.read_csv(\"../datasets/assignment/test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_train_input=train_data['userId'].values.tolist()\n",
    "user_test_input=test_data['userId'].values.tolist()\n",
    "\n",
    "item_train_input=train_data['movieId'].values.tolist()\n",
    "item_test_input=test_data['movieId'].values.tolist()\n",
    "\n",
    "label_train_input=train_data['preference'].values.tolist()\n",
    "label_test_input=test_data['preference'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_users=len(train_data.userId.unique())+1\n",
    "num_items=max(item_train_input)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_all=NMFModel(user_train_input, item_train_input, label_train_input, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_result(pred_result, label_test_input):\n",
    "    ans=0\n",
    "    for i in range(len(pred_result)):\n",
    "        if label_test_input==0:\n",
    "            continue\n",
    "        elif label_test_input[i]==1 and pred_result[i]>0:\n",
    "            ans+=1\n",
    "        elif label_test_input[i]==-1 and pred_result[i]<0:\n",
    "            ans+=1\n",
    "        else:\n",
    "            ans-=1\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_model=model_all.get_mlp_model(num_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 32)        4431808     user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 1, 32)        4175712     item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 32)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 32)           0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64)           0           flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer1 (Dense)                  (None, 64)           4160        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64)           256         layer1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer2 (Dense)                  (None, 32)           2080        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32)           128         layer2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            33          batch_normalization_6[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 8,614,177\n",
      "Trainable params: 8,613,985\n",
      "Non-trainable params: 192\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_all.print_graph('mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15971866 samples\n",
      "15971840/15971866 [============================>.] - ETA: 0s - loss: 0.5000 - mae: 0.5000 - mse: 0.6363\n",
      "Epoch 00001: saving model to ./pretrained/training_1/mlp\n",
      "15971866/15971866 [==============================] - 3032s 190us/sample - loss: 0.5000 - mae: 0.5000 - mse: 0.6363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26cff46d8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all.fit_model(mlp_model, './pretrained/training_1/mlp', n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_pred=model_all.predict('mlp', user_test_input, item_test_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "717393"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_result(mlp_pred, label_test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmf_model=model_all.get_gmf_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes (1,) and (128,) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9faaa8665b24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gmf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./pretrained/training_1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/own/recommendation/nmf_model.py\u001b[0m in \u001b[0;36mload_weight\u001b[0;34m(self, model_name, cp_path)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'gmf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mlp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nmf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model name parameter must be gmf, mlp, nmf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;34m'gmf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgmf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcp_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgmf_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'mlp'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/own/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m    232\u001b[0m         raise ValueError('Load weights is not yet supported with TPUStrategy '\n\u001b[1;32m    233\u001b[0m                          'with steps_per_run greater than 1.')\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/own/env/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0msave_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m       \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trackable_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         raise NotImplementedError(\n",
      "\u001b[0;32m~/own/env/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, save_path)\u001b[0m\n\u001b[1;32m   1281\u001b[0m         graph_view=self._graph_view)\n\u001b[1;32m   1282\u001b[0m     base.CheckpointPosition(\n\u001b[0;32m-> 1283\u001b[0;31m         checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)\n\u001b[0m\u001b[1;32m   1284\u001b[0m     load_status = CheckpointLoadStatus(\n\u001b[1;32m   1285\u001b[0m         \u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/own/env/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, trackable)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;31m# This object's correspondence with a checkpointed object is new, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m# process deferred restorations for it and its dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_from_checkpoint_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestore_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/own/env/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_restore_from_checkpoint_position\u001b[0;34m(self, checkpoint_position)\u001b[0m\n\u001b[1;32m    906\u001b[0m     restore_ops.extend(\n\u001b[1;32m    907\u001b[0m         current_position.checkpoint.restore_saveables(\n\u001b[0;32m--> 908\u001b[0;31m             tensor_saveables, python_saveables))\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/own/env/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore_saveables\u001b[0;34m(self, tensor_saveables, python_saveables)\u001b[0m\n\u001b[1;32m    287\u001b[0m              \"expecting %s\") % (tensor_saveables.keys(), validated_names))\n\u001b[1;32m    288\u001b[0m       new_restore_ops = functional_saver.MultiDeviceSaver(\n\u001b[0;32m--> 289\u001b[0;31m           validated_saveables).restore(self.save_path_tensor)\n\u001b[0m\u001b[1;32m    290\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/own/env/lib/python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, file_prefix)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_single_device_savers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mrestore_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/own/env/lib/python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, file_prefix)\u001b[0m\n\u001b[1;32m    100\u001b[0m                                           structured_restored_tensors):\n\u001b[1;32m    101\u001b[0m       restore_ops[saveable.name] = saveable.restore(\n\u001b[0;32m--> 102\u001b[0;31m           restored_tensors, restored_shapes=None)\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/own/env/lib/python3.7/site-packages/tensorflow_core/python/training/saving/saveable_object_util.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, restored_tensors, restored_shapes)\u001b[0m\n\u001b[1;32m    114\u001b[0m       \u001b[0mrestored_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestored_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m       return resource_variable_ops.shape_safe_assign_variable_handle(\n\u001b[0;32m--> 116\u001b[0;31m           self.handle_op, self._var_shape, restored_tensor)\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/own/env/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mshape_safe_assign_variable_handle\u001b[0;34m(handle, shape, value, name)\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0m_handle_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0mvalue_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m   \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m   return gen_resource_variable_ops.assign_variable_op(handle,\n\u001b[1;32m    299\u001b[0m                                                       \u001b[0mvalue_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/own/env/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \"\"\"\n\u001b[1;32m   1109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (1,) and (128,) are incompatible"
     ]
    }
   ],
   "source": [
    "model_all.load_weight('gmf', './pretrained/training_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 16)        2215904     user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 1, 16)        2087856     item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 16)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 16)           0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 16)           0           flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16)           64          multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          2176        batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            129         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 4,306,129\n",
      "Trainable params: 4,306,097\n",
      "Non-trainable params: 32\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_all.print_graph('gmf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15971866 samples\n",
      "15971840/15971866 [============================>.] - ETA: 0s - loss: 0.6445 - mae: 0.6445 - mse: 1.0302\n",
      "Epoch 00001: saving model to ./pretrained/training_1\n",
      "15971866/15971866 [==============================] - 1584s 99us/sample - loss: 0.6445 - mae: 0.6445 - mse: 1.0302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29b6a0128>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all.fit_model(gmf_model, './pretrained/training_1', n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gmf_pred=model_all.predict('gmf', user_test_input, item_test_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382161"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_result(gmf_pred, label_test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_input_layer=layers.Input(shape=(1,), dtype='int32', name='user_input')\n",
    "item_input_layer=layers.Input(shape=(1,), dtype='int32', name='item_input')\n",
    "        \n",
    "#num_users=self.num_users\n",
    "#num_items=self.num_items\n",
    "        \n",
    "num_factors=16\n",
    "num_layers=3\n",
    "layer1_dim=num_factors*(2**(num_layers-1))\n",
    "\n",
    "\n",
    "# GMF embedding layer\n",
    "GMF_user_embedding=layers.Embedding(input_dim=num_users, output_dim=(int)(num_factors), embeddings_regularizer=regularizers.l2(0.), name='GMF_user_embedding', input_length=1)\n",
    "GMF_item_embedding=layers.Embedding(input_dim=num_items, output_dim=(int)(num_factors), embeddings_regularizer=regularizers.l2(0.), name='GMF_item_embedding', input_length=1)\n",
    "\n",
    "# MLP embedding layer\n",
    "MLP_user_embedding=layers.Embedding(input_dim=num_users, output_dim=(int)(layer1_dim/2), embeddings_regularizer=regularizers.l2(0.), name='MLP_user_embedding', input_length=1)\n",
    "MLP_item_embedding=layers.Embedding(input_dim=num_items, output_dim=(int)(layer1_dim/2), embeddings_regularizer=regularizers.l2(0.), name='MLP_item_embedding', input_length=1)\n",
    "\n",
    "#flatten GMF embedding vector\n",
    "GMF_user_latent=layers.Flatten()(GMF_user_embedding(user_input_layer))\n",
    "GMF_item_latent=layers.Flatten()(GMF_item_embedding(item_input_layer))\n",
    "\n",
    "# flatten MLP embeddding vector\n",
    "MLP_user_latent=layers.Flatten()(MLP_user_embedding(user_input_layer))\n",
    "MLP_item_latent=layers.Flatten()(MLP_item_embedding(item_input_layer))\n",
    "        \n",
    "# gmf - element wise product\n",
    "GMF_vector=layers.multiply([GMF_user_latent, GMF_item_latent])\n",
    "GMF_vector=layers.BatchNormalization()(GMF_vector)\n",
    "# 나중에 삭제해도 될 듯(잘못만든듯)\n",
    "GMF_vector=layers.Dense(128, activation='tanh')(GMF_vector)\n",
    "        \n",
    "# mlp\n",
    "MLP_vector=layers.concatenate([MLP_user_latent, MLP_item_latent])\n",
    "MLP_vector=layers.BatchNormalization()(MLP_vector)\n",
    "        \n",
    "for i in range(num_layers-1):\n",
    "    MLP_vector=layers.Dense((int)(layer1_dim/(2**i)), activation='tanh', name='layer%s' %str(i+1))(MLP_vector)\n",
    "    MLP_vector=layers.BatchNormalization()(MLP_vector)\n",
    "\n",
    "#NeuMF layer\n",
    "NeuMF_vector=layers.concatenate([GMF_vector, MLP_vector])\n",
    "prediction=layers.Dense(1, activation='tanh', name='prediction')(NeuMF_vector)\n",
    "        \n",
    "model=Model([user_input_layer, item_input_layer], prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "MLP_user_embedding (Embedding)  (None, 1, 32)        4431808     user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "MLP_item_embedding (Embedding)  (None, 1, 32)        4175712     item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_46 (Flatten)            (None, 32)           0           MLP_user_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_47 (Flatten)            (None, 32)           0           MLP_item_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 64)           0           flatten_46[0][0]                 \n",
      "                                                                 flatten_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GMF_user_embedding (Embedding)  (None, 1, 16)        2215904     user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GMF_item_embedding (Embedding)  (None, 1, 16)        2087856     item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 64)           256         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_44 (Flatten)            (None, 16)           0           GMF_user_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_45 (Flatten)            (None, 16)           0           GMF_item_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "layer1 (Dense)                  (None, 64)           4160        batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 16)           0           flatten_44[0][0]                 \n",
      "                                                                 flatten_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 64)           256         layer1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16)           64          multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer2 (Dense)                  (None, 32)           2080        batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          2176        batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 32)           128         layer2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 160)          0           dense_2[0][0]                    \n",
      "                                                                 batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            161         concatenate_15[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 12,920,561\n",
      "Trainable params: 12,920,209\n",
      "Non-trainable params: 352\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## get weight\n",
    "#GMF embedding\n",
    "gmf_user_embedding=gmf_model.get_layer('user_embedding').get_weights()\n",
    "gmf_item_embedding=gmf_model.get_layer('item_embedding').get_weights()\n",
    "model.get_layer('GMF_user_embedding').set_weights(gmf_user_embedding)\n",
    "model.get_layer('GMF_item_embedding').set_weights(gmf_item_embedding)\n",
    "\n",
    "#MLP embedding\n",
    "mlp_user_embedding=mlp_model.get_layer('user_embedding').get_weights()\n",
    "mlp_item_embedding=mlp_model.get_layer('item_embedding').get_weights()\n",
    "model.get_layer('MLP_user_embedding').set_weights(mlp_user_embedding)\n",
    "model.get_layer('MLP_item_embedding').set_weights(mlp_item_embedding)\n",
    "        \n",
    "for i in range(num_layers-1):\n",
    "    tmp=str(i+1)\n",
    "    mlp_layer=mlp_model.get_layer('layer%s' %tmp).get_weights()\n",
    "    model.get_layer('layer%s' %tmp).set_weights(mlp_layer)\n",
    "\n",
    "#prediction layer\n",
    "gmf_prediction=gmf_model.get_layer('prediction').get_weights()\n",
    "mlp_prediction=mlp_model.get_layer('prediction').get_weights()\n",
    "        \n",
    "new_weights=np.concatenate((gmf_prediction[0], mlp_prediction[0]), axis=0)\n",
    "#new_b=gmf_prediction[1]+ mlp_prediction[1]\n",
    "model.get_layer('prediction').set_weights([0.5*new_weights, 0.5*new_b])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15971866 samples\n",
      " 4800256/15971866 [========>.....................] - ETA: 53:28 - loss: 0.4774 - mae: 0.4774 - mse: 0.6166"
     ]
    }
   ],
   "source": [
    "model_all.fit_model(model, './pretrained/training_1/nmf', n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
