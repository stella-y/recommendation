{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nmf_model import NMFModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(\"../datasets/assignment/train_set.csv\")\n",
    "test_data=pd.read_csv(\"../datasets/assignment/test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_train_input=train_data['userId'].values.tolist()\n",
    "user_test_input=test_data['userId'].values.tolist()\n",
    "\n",
    "item_train_input=train_data['movieId'].values.tolist()\n",
    "item_test_input=test_data['movieId'].values.tolist()\n",
    "\n",
    "label_train_input=train_data['preference'].values.tolist()\n",
    "label_test_input=test_data['preference'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_users=len(train_data.userId.unique())+1\n",
    "num_items=max(item_train_input)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_all=NMFModel(user_train_input, item_train_input, label_train_input, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_result(pred_result, label_test_input):\n",
    "    ans=0\n",
    "    for i in range(len(pred_result)):\n",
    "        if label_test_input==0:\n",
    "            continue\n",
    "        elif label_test_input[i]==1 and pred_result[i]>0:\n",
    "            ans+=1\n",
    "        elif label_test_input[i]==-1 and pred_result[i]<0:\n",
    "            ans+=1\n",
    "        else:\n",
    "            ans-=1\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model=model_all.get_mlp_model(num_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 32)        4431808     user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 1, 32)        4175712     item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 32)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 32)           0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64)           0           flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer1 (Dense)                  (None, 64)           4160        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64)           256         layer1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer2 (Dense)                  (None, 32)           2080        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32)           128         layer2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            33          batch_normalization_6[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 8,614,177\n",
      "Trainable params: 8,613,985\n",
      "Non-trainable params: 192\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_all.print_graph('mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15971866 samples\n",
      "15971840/15971866 [============================>.] - ETA: 0s - loss: 0.5000 - mae: 0.5000 - mse: 0.6363\n",
      "Epoch 00001: saving model to ./pretrained/training_1/mlp\n",
      "15971866/15971866 [==============================] - 3032s 190us/sample - loss: 0.5000 - mae: 0.5000 - mse: 0.6363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26cff46d8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all.fit_model(mlp_model, './pretrained/training_1/mlp', n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_pred=model_all.predict('mlp', user_test_input, item_test_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "717393"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_result(mlp_pred, label_test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gmf_model=model_all.get_gmf_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 16)        2215904     user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 1, 16)        2087856     item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 16)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 16)           0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 16)           0           flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16)           64          multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          2176        batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            129         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 4,306,129\n",
      "Trainable params: 4,306,097\n",
      "Non-trainable params: 32\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_all.print_graph('gmf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15971866 samples\n",
      "15971840/15971866 [============================>.] - ETA: 0s - loss: 0.6445 - mae: 0.6445 - mse: 1.0302\n",
      "Epoch 00001: saving model to ./pretrained/training_1\n",
      "15971866/15971866 [==============================] - 1584s 99us/sample - loss: 0.6445 - mae: 0.6445 - mse: 1.0302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29b6a0128>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all.fit_model(gmf_model, './pretrained/training_1', n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmf_pred=model_all.predict('gmf', user_test_input, item_test_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382161"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_result(gmf_pred, label_test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input_layer=layers.Input(shape=(1,), dtype='int32', name='user_input')\n",
    "item_input_layer=layers.Input(shape=(1,), dtype='int32', name='item_input')\n",
    "        \n",
    "#num_users=self.num_users\n",
    "#num_items=self.num_items\n",
    "        \n",
    "num_factors=16\n",
    "num_layers=3\n",
    "layer1_dim=num_factors*(2**(num_layers-1))\n",
    "\n",
    "\n",
    "# GMF embedding layer\n",
    "GMF_user_embedding=layers.Embedding(input_dim=num_users, output_dim=(int)(num_factors), embeddings_regularizer=regularizers.l2(0.), name='GMF_user_embedding', input_length=1)\n",
    "GMF_item_embedding=layers.Embedding(input_dim=num_items, output_dim=(int)(num_factors), embeddings_regularizer=regularizers.l2(0.), name='GMF_item_embedding', input_length=1)\n",
    "\n",
    "# MLP embedding layer\n",
    "MLP_user_embedding=layers.Embedding(input_dim=num_users, output_dim=(int)(layer1_dim/2), embeddings_regularizer=regularizers.l2(0.), name='MLP_user_embedding', input_length=1)\n",
    "MLP_item_embedding=layers.Embedding(input_dim=num_items, output_dim=(int)(layer1_dim/2), embeddings_regularizer=regularizers.l2(0.), name='MLP_item_embedding', input_length=1)\n",
    "\n",
    "#flatten GMF embedding vector\n",
    "GMF_user_latent=layers.Flatten()(GMF_user_embedding(user_input_layer))\n",
    "GMF_item_latent=layers.Flatten()(GMF_item_embedding(item_input_layer))\n",
    "\n",
    "# flatten MLP embeddding vector\n",
    "MLP_user_latent=layers.Flatten()(MLP_user_embedding(user_input_layer))\n",
    "MLP_item_latent=layers.Flatten()(MLP_item_embedding(item_input_layer))\n",
    "        \n",
    "# gmf - element wise product\n",
    "GMF_vector=layers.multiply([GMF_user_latent, GMF_item_latent])\n",
    "GMF_vector=layers.BatchNormalization()(GMF_vector)\n",
    "# 나중에 삭제해도 될 듯(잘못만든듯)\n",
    "GMF_vector=layers.Dense(128, activation='tanh')(GMF_vector)\n",
    "        \n",
    "# mlp\n",
    "MLP_vector=layers.concatenate([MLP_user_latent, MLP_item_latent])\n",
    "MLP_vector=layers.BatchNormalization()(MLP_vector)\n",
    "        \n",
    "for i in range(num_layers-1):\n",
    "    MLP_vector=layers.Dense((int)(layer1_dim/(2**i)), activation='tanh', name='layer%s' %str(i+1))(MLP_vector)\n",
    "    MLP_vector=layers.BatchNormalization()(MLP_vector)\n",
    "\n",
    "#NeuMF layer\n",
    "NeuMF_vector=layers.concatenate([GMF_vector, MLP_vector])\n",
    "prediction=layers.Dense(1, activation='tanh', name='prediction')(NeuMF_vector)\n",
    "        \n",
    "model=Model([user_input_layer, item_input_layer], prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "MLP_user_embedding (Embedding)  (None, 1, 32)        4431808     user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "MLP_item_embedding (Embedding)  (None, 1, 32)        4175712     item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_46 (Flatten)            (None, 32)           0           MLP_user_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_47 (Flatten)            (None, 32)           0           MLP_item_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 64)           0           flatten_46[0][0]                 \n",
      "                                                                 flatten_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GMF_user_embedding (Embedding)  (None, 1, 16)        2215904     user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "GMF_item_embedding (Embedding)  (None, 1, 16)        2087856     item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 64)           256         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_44 (Flatten)            (None, 16)           0           GMF_user_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_45 (Flatten)            (None, 16)           0           GMF_item_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "layer1 (Dense)                  (None, 64)           4160        batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 16)           0           flatten_44[0][0]                 \n",
      "                                                                 flatten_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 64)           256         layer1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16)           64          multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "layer2 (Dense)                  (None, 32)           2080        batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          2176        batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 32)           128         layer2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 160)          0           dense_2[0][0]                    \n",
      "                                                                 batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            161         concatenate_15[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 12,920,561\n",
      "Trainable params: 12,920,209\n",
      "Non-trainable params: 352\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get weight\n",
    "#GMF embedding\n",
    "gmf_user_embedding=gmf_model.get_layer('user_embedding').get_weights()\n",
    "gmf_item_embedding=gmf_model.get_layer('item_embedding').get_weights()\n",
    "model.get_layer('GMF_user_embedding').set_weights(gmf_user_embedding)\n",
    "model.get_layer('GMF_item_embedding').set_weights(gmf_item_embedding)\n",
    "\n",
    "#MLP embedding\n",
    "mlp_user_embedding=mlp_model.get_layer('user_embedding').get_weights()\n",
    "mlp_item_embedding=mlp_model.get_layer('item_embedding').get_weights()\n",
    "model.get_layer('MLP_user_embedding').set_weights(mlp_user_embedding)\n",
    "model.get_layer('MLP_item_embedding').set_weights(mlp_item_embedding)\n",
    "        \n",
    "for i in range(num_layers-1):\n",
    "    tmp=str(i+1)\n",
    "    mlp_layer=mlp_model.get_layer('layer%s' %tmp).get_weights()\n",
    "    model.get_layer('layer%s' %tmp).set_weights(mlp_layer)\n",
    "\n",
    "#prediction layer\n",
    "gmf_prediction=gmf_model.get_layer('prediction').get_weights()\n",
    "mlp_prediction=mlp_model.get_layer('prediction').get_weights()\n",
    "        \n",
    "new_weights=np.concatenate((gmf_prediction[0], mlp_prediction[0]), axis=0)\n",
    "#new_b=gmf_prediction[1]+ mlp_prediction[1]\n",
    "model.get_layer('prediction').set_weights([0.5*new_weights, 0.5*new_b])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15971866 samples\n",
      "15971840/15971866 [============================>.] - ETA: 0s - loss: 0.4765 - mae: 0.4765 - mse: 0.6179\n",
      "Epoch 00001: saving model to ./pretrained/training_1/nmf\n",
      "15971866/15971866 [==============================] - 4538s 284us/sample - loss: 0.4765 - mae: 0.4765 - mse: 0.6179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2bc4ad438>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all.fit_model(model, './pretrained/training_1/nmf', n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_result = model.predict([np.array(user_test_input), np.array(item_test_input)]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "728409"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_result(pred_result, label_test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
