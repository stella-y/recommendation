{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nmf_model import NMFModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(\"../datasets/assignment/train_set.csv\")\n",
    "test_data=pd.read_csv(\"../datasets/assignment/test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_train_input=train_data['userId'].values.tolist()\n",
    "user_test_input=test_data['userId'].values.tolist()\n",
    "\n",
    "item_train_input=train_data['movieId'].values.tolist()\n",
    "item_test_input=test_data['movieId'].values.tolist()\n",
    "\n",
    "label_train_input=train_data['preference'].values.tolist()\n",
    "label_test_input=test_data['preference'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_users=len(train_data.userId.unique())+1\n",
    "num_items=max(item_train_input)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_all=NMFModel(user_train_input, item_train_input, label_train_input, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_result(pred_result, label_test_input):\n",
    "    ans=0\n",
    "    for i in range(len(pred_result)):\n",
    "        if label_test_input==0:\n",
    "            continue\n",
    "        elif label_test_input[i]==1 and pred_result[i]>0:\n",
    "            ans+=1\n",
    "        elif label_test_input[i]==-1 and pred_result[i]<0:\n",
    "            ans+=1\n",
    "        else:\n",
    "            ans-=1\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmf_model=model_all.get_gmf_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 16)        2215904     user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 1, 16)        2087856     item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 16)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 16)           0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 16)           0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 16)           64          multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            17          batch_normalization[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 4,303,841\n",
      "Trainable params: 4,303,809\n",
      "Non-trainable params: 32\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_all.print_graph('gmf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15971866 samples\n",
      "Epoch 1/5\n",
      "15971584/15971866 [============================>.] - ETA: 0s - loss: 0.4166 - mae: 0.5080 - mse: 0.4166\n",
      "Epoch 00001: saving model to ./pretrained/training_2/gmf\n",
      "15971866/15971866 [==============================] - 1338s 84us/sample - loss: 0.4166 - mae: 0.5080 - mse: 0.4166\n",
      "Epoch 2/5\n",
      "15971328/15971866 [============================>.] - ETA: 0s - loss: 0.3959 - mae: 0.4887 - mse: 0.3959\n",
      "Epoch 00002: saving model to ./pretrained/training_2/gmf\n",
      "15971866/15971866 [==============================] - 1329s 83us/sample - loss: 0.3959 - mae: 0.4887 - mse: 0.3959\n",
      "Epoch 3/5\n",
      "15971584/15971866 [============================>.] - ETA: 0s - loss: 0.3842 - mae: 0.4775 - mse: 0.3842\n",
      "Epoch 00003: saving model to ./pretrained/training_2/gmf\n",
      "15971866/15971866 [==============================] - 1337s 84us/sample - loss: 0.3842 - mae: 0.4775 - mse: 0.3842\n",
      "Epoch 4/5\n",
      "15971840/15971866 [============================>.] - ETA: 0s - loss: 0.3767 - mae: 0.4702 - mse: 0.3767\n",
      "Epoch 00004: saving model to ./pretrained/training_2/gmf\n",
      "15971866/15971866 [==============================] - 1333s 83us/sample - loss: 0.3767 - mae: 0.4702 - mse: 0.3767\n",
      "Epoch 5/5\n",
      "15971840/15971866 [============================>.] - ETA: 0s - loss: 0.3714 - mae: 0.4649 - mse: 0.3714\n",
      "Epoch 00005: saving model to ./pretrained/training_2/gmf\n",
      "15971866/15971866 [==============================] - 1331s 83us/sample - loss: 0.3714 - mae: 0.4649 - mse: 0.3714\n"
     ]
    }
   ],
   "source": [
    "gmf_hist=model_all.fit_model('gmf', './pretrained/training_2/gmf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gmf_pred=model_all.predict('gmf', user_test_input, item_test_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "928167"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_result(gmf_pred, label_test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_model=model_all.get_mlp_model(num_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 32)        4431808     user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 1, 32)        4175712     item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 32)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 32)           0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64)           0           flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer1 (Dense)                  (None, 64)           4160        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64)           256         layer1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer2 (Dense)                  (None, 32)           2080        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32)           128         layer2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            33          batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 8,614,177\n",
      "Trainable params: 8,613,985\n",
      "Non-trainable params: 192\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_all.print_graph('mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15971866 samples\n",
      "Epoch 1/5\n",
      "15971840/15971866 [============================>.] - ETA: 0s - loss: 0.4824 - mae: 0.5727 - mse: 0.4824\n",
      "Epoch 00001: saving model to ./pretrained/training_2/mlp\n",
      "15971866/15971866 [==============================] - 22923s 1ms/sample - loss: 0.4824 - mae: 0.5727 - mse: 0.4824\n",
      "Epoch 2/5\n",
      "15971840/15971866 [============================>.] - ETA: 0s - loss: 0.4457 - mae: 0.5362 - mse: 0.4457\n",
      "Epoch 00002: saving model to ./pretrained/training_2/mlp\n",
      "15971866/15971866 [==============================] - 3068s 192us/sample - loss: 0.4457 - mae: 0.5362 - mse: 0.4457\n",
      "Epoch 3/5\n",
      "15971840/15971866 [============================>.] - ETA: 0s - loss: 0.4268 - mae: 0.5179 - mse: 0.4268\n",
      "Epoch 00003: saving model to ./pretrained/training_2/mlp\n",
      "15971866/15971866 [==============================] - 3094s 194us/sample - loss: 0.4268 - mae: 0.5179 - mse: 0.4268\n",
      "Epoch 4/5\n",
      "15971840/15971866 [============================>.] - ETA: 0s - loss: 0.4128 - mae: 0.5043 - mse: 0.4128\n",
      "Epoch 00004: saving model to ./pretrained/training_2/mlp\n",
      "15971866/15971866 [==============================] - 3040s 190us/sample - loss: 0.4128 - mae: 0.5043 - mse: 0.4128\n",
      "Epoch 5/5\n",
      "15971584/15971866 [============================>.] - ETA: 0s - loss: 0.3999 - mae: 0.4917 - mse: 0.3999\n",
      "Epoch 00005: saving model to ./pretrained/training_2/mlp\n",
      "15971866/15971866 [==============================] - 3039s 190us/sample - loss: 0.3999 - mae: 0.4917 - mse: 0.3999\n"
     ]
    }
   ],
   "source": [
    "mlp_hist=model_all.fit_model('mlp', './pretrained/training_2/mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_pred=model_all.predict('mlp', user_test_input, item_test_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "902315"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_result(mlp_pred, label_test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'set_nmf_weight' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d6baf4673129>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnmf_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_nmf_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/own/recommendation/nmf_model.py\u001b[0m in \u001b[0;36mget_nmf_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnmf_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnmf_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mset_nmf_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnmf_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'set_nmf_weight' is not defined"
     ]
    }
   ],
   "source": [
    "nmf_model=model_all.get_nmf_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_all.print_graph('nmf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf_pred=model_all.fit_model('nmf', './pretrained/training_2/nmf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf_pred=model_all.predict('nmf', user_test_input, item_test_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cal_result(nmf_pred, label_test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
