{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(\"../datasets/assignment/train_set.csv\")\n",
    "test_data=pd.read_csv(\"../datasets/assignment/test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>t</th>\n",
       "      <th>rating</th>\n",
       "      <th>preference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31231</td>\n",
       "      <td>1193</td>\n",
       "      <td>2001-03-14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32077</td>\n",
       "      <td>1284</td>\n",
       "      <td>1999-11-02</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37618</td>\n",
       "      <td>368</td>\n",
       "      <td>2008-01-25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76002</td>\n",
       "      <td>490</td>\n",
       "      <td>1996-07-04</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79452</td>\n",
       "      <td>2132</td>\n",
       "      <td>2012-05-16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15971861</th>\n",
       "      <td>127704</td>\n",
       "      <td>3505</td>\n",
       "      <td>2000-03-30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15971862</th>\n",
       "      <td>125972</td>\n",
       "      <td>1242</td>\n",
       "      <td>1999-12-14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15971863</th>\n",
       "      <td>64040</td>\n",
       "      <td>434</td>\n",
       "      <td>1996-11-19</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15971864</th>\n",
       "      <td>105127</td>\n",
       "      <td>356</td>\n",
       "      <td>2013-02-18</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15971865</th>\n",
       "      <td>72983</td>\n",
       "      <td>1887</td>\n",
       "      <td>2003-11-18</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15971866 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId           t  rating  preference\n",
       "0          31231     1193  2001-03-14     5.0         1.0\n",
       "1          32077     1284  1999-11-02     4.0         1.0\n",
       "2          37618      368  2008-01-25     3.0         0.0\n",
       "3          76002      490  1996-07-04     4.0         1.0\n",
       "4          79452     2132  2012-05-16     3.0         0.0\n",
       "...          ...      ...         ...     ...         ...\n",
       "15971861  127704     3505  2000-03-30     4.0         1.0\n",
       "15971862  125972     1242  1999-12-14     4.0         1.0\n",
       "15971863   64040      434  1996-11-19     3.0         1.0\n",
       "15971864  105127      356  2013-02-18     4.0         1.0\n",
       "15971865   72983     1887  2003-11-18     1.5        -1.0\n",
       "\n",
       "[15971866 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>t</th>\n",
       "      <th>preference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118853</td>\n",
       "      <td>4232</td>\n",
       "      <td>2002-10-11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1734</td>\n",
       "      <td>1701</td>\n",
       "      <td>2015-02-03</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65850</td>\n",
       "      <td>535</td>\n",
       "      <td>2002-07-16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99208</td>\n",
       "      <td>6832</td>\n",
       "      <td>2005-04-13</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>133444</td>\n",
       "      <td>318</td>\n",
       "      <td>2000-12-08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992962</th>\n",
       "      <td>69753</td>\n",
       "      <td>367</td>\n",
       "      <td>2008-03-14</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992963</th>\n",
       "      <td>50421</td>\n",
       "      <td>1961</td>\n",
       "      <td>2007-06-06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992964</th>\n",
       "      <td>101721</td>\n",
       "      <td>372</td>\n",
       "      <td>1997-05-11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992965</th>\n",
       "      <td>80928</td>\n",
       "      <td>2469</td>\n",
       "      <td>2001-07-16</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992966</th>\n",
       "      <td>8190</td>\n",
       "      <td>147</td>\n",
       "      <td>1997-07-19</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3992967 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId  movieId           t  preference\n",
       "0        118853     4232  2002-10-11         0.0\n",
       "1          1734     1701  2015-02-03         1.0\n",
       "2         65850      535  2002-07-16         0.0\n",
       "3         99208     6832  2005-04-13         1.0\n",
       "4        133444      318  2000-12-08         1.0\n",
       "...         ...      ...         ...         ...\n",
       "3992962   69753      367  2008-03-14        -1.0\n",
       "3992963   50421     1961  2007-06-06         0.0\n",
       "3992964  101721      372  1997-05-11         0.0\n",
       "3992965   80928     2469  2001-07-16        -1.0\n",
       "3992966    8190      147  1997-07-19         1.0\n",
       "\n",
       "[3992967 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0., -1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.preference.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_train_input=train_data['userId'].values.tolist()\n",
    "user_test_input=test_data['userId'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_train_input=train_data['movieId'].values.tolist()\n",
    "item_test_input=test_data['movieId'].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_train_input=train_data['preference'].values.tolist()\n",
    "label_test_input=test_data['preference'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_train_input_len: 15971866\n",
      "user_train_input_max: 138493\n",
      "train_user_id_unique: 138493\n",
      "item_train_input_len: 15971866\n",
      "item_train_input_max: 130490\n",
      "train_item_id_unique: 15451\n"
     ]
    }
   ],
   "source": [
    "print(\"user_train_input_len: \" +str(len(user_train_input)))\n",
    "print(\"user_train_input_max: \"+str(max(user_train_input)))\n",
    "print(\"train_user_id_unique: \"+str(len(train_data.userId.unique())))\n",
    "print(\"item_train_input_len: \" +str(len(item_train_input)))\n",
    "print(\"item_train_input_max: \"+str(max(item_train_input)))\n",
    "print(\"train_item_id_unique: \"+str(len(train_data.movieId.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_test_input_len: 3992967\n",
      "user_test_input_max: 138493\n",
      "test_user_id_unique: 138325\n",
      "item_test_input_len: 3992967\n",
      "item_test_input_max: 130490\n",
      "test_item_id_unique: 15343\n"
     ]
    }
   ],
   "source": [
    "print(\"user_test_input_len: \" +str(len(user_test_input)))\n",
    "print(\"user_test_input_max: \"+str(max(user_test_input)))\n",
    "print(\"test_user_id_unique: \"+str(len(test_data.userId.unique())))\n",
    "print(\"item_test_input_len: \" +str(len(item_test_input)))\n",
    "print(\"item_test_input_max: \"+str(max(item_test_input)))\n",
    "print(\"test_item_id_unique: \"+str(len(test_data.movieId.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_users=len(train_data.userId.unique())\n",
    "num_items=len(train_data.movieId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_users=len(train_data.userId.unique())+1\n",
    "num_items=max(item_train_input)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138494\n",
      "130491\n"
     ]
    }
   ],
   "source": [
    "print(num_users)\n",
    "print(num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_factors=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import regularizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input layer\n",
    "user_input_layer=layers.Input(shape=(1,), dtype='int32', name='user_input')\n",
    "item_input_layer=layers.Input(shape=(1,), dtype='int32', name='item_input')\n",
    "\n",
    "# embedding layer\n",
    "user_embedding_layer=layers.Embedding(input_dim=num_users, \n",
    "                               output_dim=num_factors, \n",
    "                               embeddings_regularizer=regularizers.l2(0.),\n",
    "                               name='user_embedding'\n",
    "                              )(user_input_layer)\n",
    "item_embedding_layer=layers.Embedding(input_dim=num_items, \n",
    "                               output_dim=num_factors, \n",
    "                               embeddings_regularizer=regularizers.l2(0.),\n",
    "                               name='item_embedding'\n",
    "                              )(item_input_layer)\n",
    "\n",
    "# flatten embedding vector\n",
    "user_latent=layers.Flatten()(user_embedding_layer)\n",
    "item_latent=layers.Flatten()(item_embedding_layer)\n",
    "\n",
    "# element wise product\n",
    "ew_product=layers.multiply([user_latent, item_latent])\n",
    "ew_product=layers.BatchNormalization()(ew_product)\n",
    "\n",
    "dense=layers.Dense(128, activation='tanh')(ew_product)\n",
    "prediction=layers.Dense(1, activation='tanh', name='prediction')(dense)\n",
    "\n",
    "model=Model([user_input_layer, item_input_layer], prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embedding (Embedding)      (None, 1, 16)        2215904     user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "item_embedding (Embedding)      (None, 1, 16)        2087856     item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 16)           0           user_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 16)           0           item_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 16)           0           flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16)           64          multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          2176        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Dense)              (None, 1)            129         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,306,129\n",
      "Trainable params: 4,306,097\n",
      "Non-trainable params: 32\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',\n",
    "              optimizer='adam',\n",
    "              metrics=['mae', 'mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "n_split=3\n",
    "for train_index,test_index in KFold(n_split).split(X):\n",
    "    user_train, user_validation=user_train_input[train_index], user_train_input[test_index]\n",
    "    item_train, item_validation=item_train_input[train_index], item_train_input[test_index]\n",
    "    label_train, label_validation=label_train_input[train_index], label_train_input[test_index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path=\"training_2/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15971866 samples\n",
      "Epoch 1/20\n",
      "15971840/15971866 [============================>.] - ETA: 0s - loss: 0.4645 - mae: 0.5550 - mse: 0.4645\n",
      "Epoch 00001: saving model to training_2/cp.ckpt\n",
      "15971866/15971866 [==============================] - 6037s 378us/sample - loss: 0.4645 - mae: 0.5550 - mse: 0.4645\n",
      "Epoch 2/20\n",
      "15971776/15971866 [============================>.] - ETA: 0s - loss: 0.4331 - mae: 0.5246 - mse: 0.4331\n",
      "Epoch 00002: saving model to training_2/cp.ckpt\n",
      "15971866/15971866 [==============================] - 5940s 372us/sample - loss: 0.4331 - mae: 0.5246 - mse: 0.4331\n",
      "Epoch 3/20\n",
      "15971776/15971866 [============================>.] - ETA: 0s - loss: 0.4150 - mae: 0.5067 - mse: 0.4150\n",
      "Epoch 00003: saving model to training_2/cp.ckpt\n",
      "15971866/15971866 [==============================] - 6052s 379us/sample - loss: 0.4150 - mae: 0.5067 - mse: 0.4150\n",
      "Epoch 4/20\n",
      "15971840/15971866 [============================>.] - ETA: 0s - loss: 0.4035 - mae: 0.4953 - mse: 0.4035\n",
      "Epoch 00004: saving model to training_2/cp.ckpt\n",
      "15971866/15971866 [==============================] - 6008s 376us/sample - loss: 0.4035 - mae: 0.4953 - mse: 0.4035\n",
      "Epoch 5/20\n",
      "15971776/15971866 [============================>.] - ETA: 0s - loss: 0.3959 - mae: 0.4876 - mse: 0.3959\n",
      "Epoch 00005: saving model to training_2/cp.ckpt\n",
      "15971866/15971866 [==============================] - 6169s 386us/sample - loss: 0.3959 - mae: 0.4876 - mse: 0.3959\n",
      "Epoch 6/20\n",
      "15971712/15971866 [============================>.] - ETA: 0s - loss: 0.3905 - mae: 0.4821 - mse: 0.3905\n",
      "Epoch 00006: saving model to training_2/cp.ckpt\n",
      "15971866/15971866 [==============================] - 6069s 380us/sample - loss: 0.3905 - mae: 0.4821 - mse: 0.3905\n",
      "Epoch 7/20\n",
      "15971840/15971866 [============================>.] - ETA: 0s - loss: 0.3866 - mae: 0.4780 - mse: 0.3866\n",
      "Epoch 00007: saving model to training_2/cp.ckpt\n",
      "15971866/15971866 [==============================] - 5763s 361us/sample - loss: 0.3866 - mae: 0.4780 - mse: 0.3866\n",
      "Epoch 8/20\n",
      "15971776/15971866 [============================>.] - ETA: 0s - loss: 0.3836 - mae: 0.4749 - mse: 0.3836\n",
      "Epoch 00008: saving model to training_2/cp.ckpt\n",
      "15971866/15971866 [==============================] - 5896s 369us/sample - loss: 0.3836 - mae: 0.4749 - mse: 0.3836\n",
      "Epoch 9/20\n",
      "15971712/15971866 [============================>.] - ETA: 0s - loss: 0.3812 - mae: 0.4722 - mse: 0.3812\n",
      "Epoch 00009: saving model to training_2/cp.ckpt\n",
      "15971866/15971866 [==============================] - 5890s 369us/sample - loss: 0.3812 - mae: 0.4722 - mse: 0.3812\n",
      "Epoch 10/20\n",
      "15971776/15971866 [============================>.] - ETA: 0s - loss: 0.3791 - mae: 0.4700 - mse: 0.3791\n",
      "Epoch 00010: saving model to training_2/cp.ckpt\n",
      "15971866/15971866 [==============================] - 5964s 373us/sample - loss: 0.3791 - mae: 0.4700 - mse: 0.3791\n",
      "Epoch 11/20\n",
      "15971840/15971866 [============================>.] - ETA: 0s - loss: 0.3775 - mae: 0.4683 - mse: 0.3775\n",
      "Epoch 00011: saving model to training_2/cp.ckpt\n",
      "15971866/15971866 [==============================] - 5921s 371us/sample - loss: 0.3775 - mae: 0.4683 - mse: 0.3775\n",
      "Epoch 12/20\n",
      "15971776/15971866 [============================>.] - ETA: 0s - loss: 0.3760 - mae: 0.4667 - mse: 0.3760\n",
      "Epoch 00012: saving model to training_2/cp.ckpt\n",
      "15971866/15971866 [==============================] - 6075s 380us/sample - loss: 0.3760 - mae: 0.4667 - mse: 0.3760\n",
      "Epoch 13/20\n",
      "15971712/15971866 [============================>.] - ETA: 0s - loss: 0.3749 - mae: 0.4654 - mse: 0.3749\n",
      "Epoch 00013: saving model to training_2/cp.ckpt\n",
      "15971866/15971866 [==============================] - 6104s 382us/sample - loss: 0.3749 - mae: 0.4654 - mse: 0.3749\n",
      "Epoch 14/20\n",
      "15971840/15971866 [============================>.] - ETA: 0s - loss: 0.3738 - mae: 0.4643 - mse: 0.3738\n",
      "Epoch 00014: saving model to training_2/cp.ckpt\n",
      "15971866/15971866 [==============================] - 7034s 440us/sample - loss: 0.3738 - mae: 0.4643 - mse: 0.3738\n",
      "Epoch 15/20\n",
      "15971712/15971866 [============================>.] - ETA: 0s - loss: 0.3729 - mae: 0.4632 - mse: 0.3729\n",
      "Epoch 00015: saving model to training_2/cp.ckpt\n",
      "15971866/15971866 [==============================] - 5972s 374us/sample - loss: 0.3729 - mae: 0.4632 - mse: 0.3729\n",
      "Epoch 16/20\n",
      "15971840/15971866 [============================>.] - ETA: 0s - loss: 0.3719 - mae: 0.4623 - mse: 0.3719\n",
      "Epoch 00016: saving model to training_2/cp.ckpt\n",
      "15971866/15971866 [==============================] - 5911s 370us/sample - loss: 0.3719 - mae: 0.4623 - mse: 0.3719\n",
      "Epoch 17/20\n",
      "15971840/15971866 [============================>.] - ETA: 0s - loss: 0.3712 - mae: 0.4615 - mse: 0.3712\n",
      "Epoch 00017: saving model to training_2/cp.ckpt\n",
      "15971866/15971866 [==============================] - 5950s 373us/sample - loss: 0.3712 - mae: 0.4615 - mse: 0.3712\n",
      "Epoch 18/20\n",
      "15971776/15971866 [============================>.] - ETA: 0s - loss: 0.3706 - mae: 0.4608 - mse: 0.3706\n",
      "Epoch 00018: saving model to training_2/cp.ckpt\n",
      "15971866/15971866 [==============================] - 5963s 373us/sample - loss: 0.3706 - mae: 0.4608 - mse: 0.3706\n",
      "Epoch 19/20\n",
      "15971776/15971866 [============================>.] - ETA: 0s - loss: 0.3700 - mae: 0.4600 - mse: 0.3700\n",
      "Epoch 00019: saving model to training_2/cp.ckpt\n",
      "15971866/15971866 [==============================] - 6015s 377us/sample - loss: 0.3700 - mae: 0.4600 - mse: 0.3700\n",
      "Epoch 20/20\n",
      "15971712/15971866 [============================>.] - ETA: 0s - loss: 0.3694 - mae: 0.4594 - mse: 0.3694\n",
      "Epoch 00020: saving model to training_2/cp.ckpt\n",
      "15971866/15971866 [==============================] - 6054s 379us/sample - loss: 0.3694 - mae: 0.4594 - mse: 0.3694\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([np.array(user_train_input), np.array(item_train_input)], \n",
    "                  np.array(label_train_input),\n",
    "                  batch_size=64,\n",
    "                  epochs=20,\n",
    "                  callbacks = [cp_callback]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.371947</td>\n",
       "      <td>0.462251</td>\n",
       "      <td>0.371945</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.371214</td>\n",
       "      <td>0.461466</td>\n",
       "      <td>0.371216</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.370591</td>\n",
       "      <td>0.460760</td>\n",
       "      <td>0.370589</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.369973</td>\n",
       "      <td>0.460026</td>\n",
       "      <td>0.369973</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.369404</td>\n",
       "      <td>0.459432</td>\n",
       "      <td>0.369405</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss       mae       mse  epoch\n",
       "15  0.371947  0.462251  0.371945     15\n",
       "16  0.371214  0.461466  0.371216     16\n",
       "17  0.370591  0.460760  0.370589     17\n",
       "18  0.369973  0.460026  0.369973     18\n",
       "19  0.369404  0.459432  0.369405     19"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict([np.array(user_test_input), np.array(item_test_input)]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=0\n",
    "for i in range(len(test_predictions)):\n",
    "    if label_test_input==0:\n",
    "        continue\n",
    "    elif label_test_input[i]==1 and test_predictions[i]>0:\n",
    "        ans+=1\n",
    "    elif label_test_input[i]==-1 and test_predictions[i]<0:\n",
    "        ans+=1\n",
    "    else:\n",
    "        ans-=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "893973\n"
     ]
    }
   ],
   "source": [
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08621738 0.35817236 0.61503    ... 0.33055553 0.07205181 0.6593466 ]\n"
     ]
    }
   ],
   "source": [
    "print(str(test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9724382"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(label_train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(label_test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a['label']=label_test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a['pred']=test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.656393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.496724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.919269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.769740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.661894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.616381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.737767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.040979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.707627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.727128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.400041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.262094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.402933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.896805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.092021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.016938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.504817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label      pred\n",
       "0     0.0  0.656393\n",
       "1     1.0  0.496724\n",
       "2     0.0  0.919269\n",
       "3     1.0  0.769740\n",
       "4     1.0  0.661894\n",
       "5     1.0  0.616381\n",
       "6     0.0  0.737767\n",
       "7     0.0 -0.040979\n",
       "8    -1.0  0.707627\n",
       "9     1.0  0.727128\n",
       "10   -1.0 -0.400041\n",
       "11    1.0  0.262094\n",
       "12    1.0 -0.402933\n",
       "13    1.0  0.896805\n",
       "14    0.0  0.047304\n",
       "15    1.0 -0.092021\n",
       "16    1.0  0.016938\n",
       "17    1.0  0.014680\n",
       "18    1.0  0.005384\n",
       "19    0.0 -0.504817"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    2187564\n",
       " 0.0    1019838\n",
       "-1.0     785565\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one(x):\n",
    "    if x<0:\n",
    "        return -1\n",
    "    elif x>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['one']=[one(i) for i in test_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    3005288\n",
       "-1     987679\n",
       "Name: one, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['one'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.861115    8\n",
       " 0.814279    8\n",
       " 0.902949    7\n",
       " 0.892830    7\n",
       " 0.906071    7\n",
       "            ..\n",
       " 0.192704    1\n",
       " 0.192704    1\n",
       "-0.192704    1\n",
       " 0.192703    1\n",
       "-0.729536    1\n",
       "Name: pred, Length: 3575905, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " ...]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_test_input[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.023696575,\n",
       " 0.5513149,\n",
       " 0.5720376,\n",
       " 0.90404993,\n",
       " 0.07423127,\n",
       " 0.073088996,\n",
       " 0.1072138,\n",
       " 0.08485682,\n",
       " 0.28691074,\n",
       " 0.015842209,\n",
       " 0.74084914,\n",
       " 0.62128884,\n",
       " 0.1403531,\n",
       " 0.0029626598,\n",
       " 0.6541801,\n",
       " 0.43505695,\n",
       " 0.00015962264,\n",
       " 0.010798017,\n",
       " 0.7794127,\n",
       " 0.026060564,\n",
       " 0.49222526,\n",
       " 0.60625905,\n",
       " 0.029416937,\n",
       " 0.0025561347,\n",
       " 0.22379093,\n",
       " 0.69869035,\n",
       " 0.0261247,\n",
       " 0.8970507,\n",
       " 6.0420894e-05,\n",
       " 0.010608318,\n",
       " 0.31576213,\n",
       " 0.7013248,\n",
       " 0.031174002,\n",
       " 0.48499605,\n",
       " 5.0564322e-05,\n",
       " 1.8319271e-06,\n",
       " 0.038226612,\n",
       " 0.08339808,\n",
       " 0.4284441,\n",
       " 0.009999825,\n",
       " 0.50652045,\n",
       " 0.38958913,\n",
       " 0.73669153,\n",
       " 0.14350939,\n",
       " 0.910863,\n",
       " 0.60107666,\n",
       " 0.7322822,\n",
       " 0.17103119,\n",
       " 0.6193472,\n",
       " 0.92816126,\n",
       " 0.30967665,\n",
       " 0.031139975,\n",
       " 0.66544724,\n",
       " 0.004225259,\n",
       " 0.40288317,\n",
       " 0.81224096,\n",
       " 0.21667722,\n",
       " 0.008793012,\n",
       " 0.58961135,\n",
       " 0.7089185,\n",
       " 0.0005027621,\n",
       " 0.5241373,\n",
       " 0.35741234,\n",
       " 0.6454831,\n",
       " 0.9600248,\n",
       " 0.8739203,\n",
       " 0.015662583,\n",
       " 0.09595481,\n",
       " 0.97680885,\n",
       " 0.6489279,\n",
       " 0.74063224,\n",
       " 0.63205725,\n",
       " 0.5795227,\n",
       " 0.046018578,\n",
       " 0.47467202,\n",
       " 0.050233584,\n",
       " 0.93432313,\n",
       " 0.003551942,\n",
       " 0.15058286,\n",
       " 0.31206274,\n",
       " 0.0012119684,\n",
       " 0.31548816,\n",
       " 0.6725527,\n",
       " 0.04519995,\n",
       " 0.9471445,\n",
       " 0.30158305,\n",
       " 0.047312453,\n",
       " 0.4575979,\n",
       " 0.5825337,\n",
       " 0.9356528,\n",
       " 0.40380827,\n",
       " 0.59376746,\n",
       " 0.06272299,\n",
       " 0.63425183,\n",
       " 0.005288466,\n",
       " 0.3580957,\n",
       " 0.36405727,\n",
       " 0.15410948,\n",
       " 0.6178264,\n",
       " 0.99035525,\n",
       " 0.0023722935,\n",
       " 0.58738834,\n",
       " 0.51777565,\n",
       " 0.87832224,\n",
       " 0.43324843,\n",
       " 0.75899696,\n",
       " 0.001957193,\n",
       " 0.24392857,\n",
       " 0.28619152,\n",
       " 0.57333463,\n",
       " 0.79917765,\n",
       " 0.97200984,\n",
       " 0.0022648156,\n",
       " 0.012767299,\n",
       " 0.58099186,\n",
       " 0.48393598,\n",
       " 0.90719527,\n",
       " 0.550484,\n",
       " 0.6288701,\n",
       " 0.0032299673,\n",
       " 0.13375247,\n",
       " 0.2324789,\n",
       " 0.15180308,\n",
       " 0.55038327,\n",
       " 0.7840291,\n",
       " 0.0829237,\n",
       " 0.2560468,\n",
       " 0.002139736,\n",
       " 0.83645076,\n",
       " 0.8741033,\n",
       " 0.8769452,\n",
       " 0.72001773,\n",
       " 0.4656167,\n",
       " 0.27757803,\n",
       " 0.5965348,\n",
       " 0.25146753,\n",
       " 0.7552373,\n",
       " 0.37755892,\n",
       " 0.96479446,\n",
       " 0.6114692,\n",
       " 0.34258568,\n",
       " 7.131929e-06,\n",
       " 0.31094,\n",
       " 0.5709879,\n",
       " 0.6761606,\n",
       " 0.3944073,\n",
       " 0.5498617,\n",
       " 0.5064182,\n",
       " 0.00097174366,\n",
       " 0.053763654,\n",
       " 0.026804263,\n",
       " 0.08272404,\n",
       " 0.08727143,\n",
       " 0.56779146,\n",
       " 0.00024159579,\n",
       " 0.2819314,\n",
       " 0.24254705,\n",
       " 0.3630447,\n",
       " 0.106295,\n",
       " 0.046282094,\n",
       " 0.060280517,\n",
       " 0.79375684,\n",
       " 0.11169781,\n",
       " 0.71327174,\n",
       " 0.58467627,\n",
       " 0.0038922746,\n",
       " 0.64699376,\n",
       " 0.52467644,\n",
       " 0.33758274,\n",
       " 0.03161465,\n",
       " 0.5500861,\n",
       " 0.9497497,\n",
       " 0.0064824694,\n",
       " 0.29949352,\n",
       " 0.24183862,\n",
       " 0.64564764,\n",
       " 0.5568626,\n",
       " 0.88852143,\n",
       " 0.0011724115,\n",
       " 0.71967846,\n",
       " 0.6762703,\n",
       " 0.34911397,\n",
       " 0.016064012,\n",
       " 0.79285496,\n",
       " 0.5810013,\n",
       " 2.4115876e-05,\n",
       " 0.23549508,\n",
       " 0.2981224,\n",
       " 0.7630508,\n",
       " 0.21079116,\n",
       " 0.3215485,\n",
       " 0.19855599,\n",
       " 0.9969434,\n",
       " 0.44370928,\n",
       " 0.2111479,\n",
       " 0.0050212545,\n",
       " 0.13816665,\n",
       " 0.8799954,\n",
       " 0.023716176,\n",
       " 0.2698215,\n",
       " 0.71424794,\n",
       " 0.3972528,\n",
       " 0.18792161,\n",
       " 0.5135368,\n",
       " 0.61243176,\n",
       " 0.64266676,\n",
       " 0.010264726,\n",
       " 0.47652668,\n",
       " 0.026364483,\n",
       " 0.50694364,\n",
       " 0.67699933,\n",
       " 0.7311249,\n",
       " 0.44094878,\n",
       " 0.6389031,\n",
       " 0.90177214,\n",
       " 0.020208206,\n",
       " 0.84846747,\n",
       " 0.23048656,\n",
       " 0.5452025,\n",
       " 0.014512811,\n",
       " 0.08787093,\n",
       " 0.19020317,\n",
       " 0.042026676,\n",
       " 0.528891,\n",
       " 0.72665304,\n",
       " 0.3949917,\n",
       " 0.008616876,\n",
       " 0.08120167,\n",
       " 0.4137255,\n",
       " 0.2878928,\n",
       " 0.810106,\n",
       " 0.0965782,\n",
       " 0.60018504,\n",
       " 0.00093251246,\n",
       " 0.78405315,\n",
       " 0.06094212,\n",
       " 0.0010242416,\n",
       " 0.9266993,\n",
       " 0.29345882,\n",
       " 0.43611166,\n",
       " 0.6973625,\n",
       " 0.4715837,\n",
       " 0.43310848,\n",
       " 0.95446783,\n",
       " 0.29180306,\n",
       " 0.005785864,\n",
       " 0.4537762,\n",
       " 0.7100793,\n",
       " 0.35673058,\n",
       " 0.5420015,\n",
       " 0.7858646,\n",
       " 0.22906236,\n",
       " 0.019413356,\n",
       " 0.05252756,\n",
       " 0.93308127,\n",
       " 0.26967475,\n",
       " 0.56417054,\n",
       " 0.45038104,\n",
       " 0.7041005,\n",
       " 0.8758982,\n",
       " 0.048105277,\n",
       " 0.0006597872,\n",
       " 0.6183866,\n",
       " 0.769261,\n",
       " 0.7188979,\n",
       " 0.090955876,\n",
       " 0.68299484,\n",
       " 0.07730648,\n",
       " 0.10215058,\n",
       " 0.94124407,\n",
       " 0.14983913,\n",
       " 0.0077973404,\n",
       " 0.104630664,\n",
       " 0.2828529,\n",
       " 0.22802596,\n",
       " 0.6080342,\n",
       " 0.7916425,\n",
       " 0.43129286,\n",
       " 0.8443315,\n",
       " 0.7261594,\n",
       " 0.26736948,\n",
       " 0.033378847,\n",
       " 0.6695158,\n",
       " 0.5884357,\n",
       " 0.30706757,\n",
       " 0.5761867,\n",
       " 0.12560242,\n",
       " 0.42988145,\n",
       " 0.300062,\n",
       " 0.00010091647,\n",
       " 0.112155415,\n",
       " 0.64871854,\n",
       " 0.0021686545,\n",
       " 0.7196529,\n",
       " 0.0010081313,\n",
       " 0.56873053,\n",
       " 0.56915516,\n",
       " 0.24589871,\n",
       " 0.08117219,\n",
       " 0.33501515,\n",
       " 0.29865134,\n",
       " 0.7367287,\n",
       " 0.37912714,\n",
       " 0.057590947,\n",
       " 0.012550852,\n",
       " 0.5999073,\n",
       " 0.86110646,\n",
       " 0.0011216556,\n",
       " 0.10653572,\n",
       " 0.42714044,\n",
       " 0.28314736,\n",
       " 0.6973547,\n",
       " 0.43653464,\n",
       " 0.5818686,\n",
       " 0.8734879,\n",
       " 0.59927535,\n",
       " 0.8285258,\n",
       " 0.8302335,\n",
       " 0.7915349,\n",
       " 0.41370055,\n",
       " 0.29387224,\n",
       " 0.39101037,\n",
       " 0.45361182,\n",
       " 0.8002863,\n",
       " 0.80607814,\n",
       " 0.0018270959,\n",
       " 0.38155937,\n",
       " 0.6013563,\n",
       " 0.8934222,\n",
       " 0.60421264,\n",
       " 0.2807124,\n",
       " 0.5246793,\n",
       " 0.65820956,\n",
       " 0.5032544,\n",
       " 0.3287212,\n",
       " 0.8063568,\n",
       " 0.015075898,\n",
       " 0.6815447,\n",
       " 0.21474615,\n",
       " 0.1899848,\n",
       " 0.6519787,\n",
       " 0.032324772,\n",
       " 0.642332,\n",
       " 0.8948869,\n",
       " 0.7400926,\n",
       " 0.30934715,\n",
       " 0.17964,\n",
       " 0.027812984,\n",
       " 0.76998043,\n",
       " 0.4502971,\n",
       " 0.4076824,\n",
       " 0.98596746,\n",
       " 5.2828054e-05,\n",
       " 2.2851347e-05,\n",
       " 0.6131056,\n",
       " 0.37625885,\n",
       " 0.02460662,\n",
       " 0.7420446,\n",
       " 0.3723051,\n",
       " 0.89753,\n",
       " 0.002419987,\n",
       " 0.34335223,\n",
       " 0.21663505,\n",
       " 0.8564305,\n",
       " 0.69420147,\n",
       " 0.564002,\n",
       " 0.66290146,\n",
       " 0.73996377,\n",
       " 0.0056642843,\n",
       " 0.6767139,\n",
       " 0.7944163,\n",
       " 0.36309245,\n",
       " 0.51101285,\n",
       " 0.6884446,\n",
       " 0.39307916,\n",
       " 0.9309484,\n",
       " 0.05352384,\n",
       " 0.62677675,\n",
       " 0.15019391,\n",
       " 0.965661,\n",
       " 0.5309149,\n",
       " 0.8846641,\n",
       " 0.66575766,\n",
       " 0.714967,\n",
       " 0.43625405,\n",
       " 0.04164506,\n",
       " 0.7324817,\n",
       " 0.1357601,\n",
       " 0.05996754,\n",
       " 0.64726615,\n",
       " 0.6611323,\n",
       " 0.95914924,\n",
       " 0.06590259,\n",
       " 0.056805264,\n",
       " 0.6245729,\n",
       " 0.6789783,\n",
       " 0.0034127254,\n",
       " 0.08879382,\n",
       " 0.64057124,\n",
       " 0.907041,\n",
       " 0.055635195,\n",
       " 0.023727383,\n",
       " 0.83163035,\n",
       " 0.90377593,\n",
       " 0.48101228,\n",
       " 0.6086357,\n",
       " 0.07719496,\n",
       " 0.004411152,\n",
       " 0.6376472,\n",
       " 0.7265812,\n",
       " 0.584133,\n",
       " 0.7392218,\n",
       " 0.12026294,\n",
       " 0.6441004,\n",
       " 0.0076216897,\n",
       " 0.64484096,\n",
       " 0.49877682,\n",
       " 0.4501446,\n",
       " 0.39459142,\n",
       " 0.8854685,\n",
       " 0.061869536,\n",
       " 0.2778756,\n",
       " 0.84167403,\n",
       " 0.23789153,\n",
       " 0.25546077,\n",
       " 0.7779829,\n",
       " 0.2290517,\n",
       " 0.1883538,\n",
       " 0.2760712,\n",
       " 0.71123606,\n",
       " 0.07870944,\n",
       " 0.9035811,\n",
       " 0.75235564,\n",
       " 0.56085426,\n",
       " 0.65097064,\n",
       " 0.17608733,\n",
       " 0.0006266187,\n",
       " 0.13774094,\n",
       " 0.8852293,\n",
       " 0.0015870611,\n",
       " 0.13759007,\n",
       " 0.63180786,\n",
       " 0.6060714,\n",
       " 0.0066204206,\n",
       " 0.608586,\n",
       " 0.40568203,\n",
       " 0.08258734,\n",
       " 2.8203347e-06,\n",
       " 0.7272381,\n",
       " 0.19371857,\n",
       " 0.086034514,\n",
       " 0.5261109,\n",
       " 0.38995868,\n",
       " 0.78480524,\n",
       " 1.8763769e-05,\n",
       " 0.22346279,\n",
       " 0.5426454,\n",
       " 0.77958435,\n",
       " 0.9779951,\n",
       " 0.81247807,\n",
       " 0.54678243,\n",
       " 0.672847,\n",
       " 0.39721358,\n",
       " 0.48480955,\n",
       " 0.53283924,\n",
       " 0.29911062,\n",
       " 0.39613435,\n",
       " 0.022349237,\n",
       " 0.03153029,\n",
       " 0.13279264,\n",
       " 0.50125724,\n",
       " 0.049015235,\n",
       " 0.3226866,\n",
       " 0.44789377,\n",
       " 0.10723581,\n",
       " 0.06336875,\n",
       " 0.6602583,\n",
       " 0.4738772,\n",
       " 0.00093974243,\n",
       " 0.37662703,\n",
       " 0.0077602975,\n",
       " 0.015538286,\n",
       " 0.029217856,\n",
       " 0.79391164,\n",
       " 0.23182727,\n",
       " 0.023929749,\n",
       " 0.9522155,\n",
       " 0.82597613,\n",
       " 0.015050771,\n",
       " 0.59553444,\n",
       " 0.93256545,\n",
       " 0.02833821,\n",
       " 0.3018344,\n",
       " 0.8153696,\n",
       " 0.85286707,\n",
       " 0.0005861821,\n",
       " 0.8806749,\n",
       " 0.0002501808,\n",
       " 0.2835496,\n",
       " 0.43785244,\n",
       " 0.96271485,\n",
       " 0.05908718,\n",
       " 0.009614955,\n",
       " 0.1481179,\n",
       " 0.5970483,\n",
       " 0.96263295,\n",
       " 0.76543516,\n",
       " 0.7309242,\n",
       " 0.015316111,\n",
       " 0.15909635,\n",
       " 0.08000382,\n",
       " 0.3606353,\n",
       " 0.16220409,\n",
       " 0.12193385,\n",
       " 0.37823698,\n",
       " 0.0017115567,\n",
       " 0.7611416,\n",
       " 0.4880577,\n",
       " 0.6824772,\n",
       " 0.9465268,\n",
       " 0.009083633,\n",
       " 0.7257371,\n",
       " 0.00029086714,\n",
       " 0.71259654,\n",
       " 0.90461355,\n",
       " 0.22422583,\n",
       " 0.05955746,\n",
       " 0.39376274,\n",
       " 0.0017506335,\n",
       " 0.08925606,\n",
       " 0.93905413,\n",
       " 0.00015521648,\n",
       " 0.26347402,\n",
       " 0.7468278,\n",
       " 0.2763612,\n",
       " 0.9575845,\n",
       " 0.580248,\n",
       " 0.8017116,\n",
       " 0.028627783,\n",
       " 0.3694598,\n",
       " 0.061273538,\n",
       " 0.8098938,\n",
       " 0.20412853,\n",
       " 0.112641364,\n",
       " 0.7824198,\n",
       " 0.0010538539,\n",
       " 0.071954146,\n",
       " 0.7075719,\n",
       " 0.98365307,\n",
       " 0.7585694,\n",
       " 0.16649595,\n",
       " 0.3322904,\n",
       " 0.2820129,\n",
       " 0.009710228,\n",
       " 0.3439164,\n",
       " 0.37022275,\n",
       " 0.76826376,\n",
       " 0.8281985,\n",
       " 0.39384598,\n",
       " 0.8195865,\n",
       " 0.475585,\n",
       " 0.05496473,\n",
       " 0.45040116,\n",
       " 0.81451386,\n",
       " 0.4493143,\n",
       " 0.44663945,\n",
       " 0.124004856,\n",
       " 0.9632196,\n",
       " 0.34611407,\n",
       " 0.83224875,\n",
       " 0.5729538,\n",
       " 0.52276194,\n",
       " 0.18642591,\n",
       " 0.39417875,\n",
       " 0.69657576,\n",
       " 0.022904668,\n",
       " 0.9332401,\n",
       " 0.15782122,\n",
       " 0.018525613,\n",
       " 0.8828813,\n",
       " 0.0020789437,\n",
       " 0.019925367,\n",
       " 0.39123186,\n",
       " 0.3607352,\n",
       " 0.067018114,\n",
       " 0.0026832586,\n",
       " 0.84238464,\n",
       " 0.23973036,\n",
       " 0.0008337012,\n",
       " 0.08474499,\n",
       " 0.67280537,\n",
       " 0.4823665,\n",
       " 0.015781093,\n",
       " 0.6356065,\n",
       " 0.81234294,\n",
       " 0.36288738,\n",
       " 0.9833504,\n",
       " 0.76946974,\n",
       " 0.016264722,\n",
       " 0.84769624,\n",
       " 0.21059977,\n",
       " 0.6017734,\n",
       " 0.8916474,\n",
       " 0.0034824214,\n",
       " 0.9501744,\n",
       " 0.16264942,\n",
       " 0.0070095644,\n",
       " 0.098168276,\n",
       " 0.800976,\n",
       " 0.25637883,\n",
       " 0.46461073,\n",
       " 0.7531947,\n",
       " 0.32845762,\n",
       " 0.07186179,\n",
       " 0.00938166,\n",
       " 0.5398917,\n",
       " 0.0057384246,\n",
       " 0.012509176,\n",
       " 0.8011262,\n",
       " 0.008288442,\n",
       " 0.7943437,\n",
       " 0.055379786,\n",
       " 0.09389973,\n",
       " 0.72283226,\n",
       " 0.23403352,\n",
       " 0.716398,\n",
       " 0.14326176,\n",
       " 0.4276341,\n",
       " 0.58819574,\n",
       " 0.8499976,\n",
       " 0.3680057,\n",
       " 0.49221492,\n",
       " 0.3514221,\n",
       " 0.81903756,\n",
       " 0.59316784,\n",
       " 0.6009319,\n",
       " 0.01483532,\n",
       " 0.09540316,\n",
       " 0.08127898,\n",
       " 0.9455189,\n",
       " 0.68884045,\n",
       " 0.2415998,\n",
       " 0.8765043,\n",
       " 0.5407443,\n",
       " 0.8460479,\n",
       " 0.09242218,\n",
       " 0.24643575,\n",
       " 0.002105627,\n",
       " 0.51612854,\n",
       " 0.86636895,\n",
       " 0.9680424,\n",
       " 0.5145493,\n",
       " 0.70478123,\n",
       " 0.00025419737,\n",
       " 0.7837525,\n",
       " 0.09900501,\n",
       " 0.6530789,\n",
       " 0.02016975,\n",
       " 0.7928534,\n",
       " 0.5897223,\n",
       " 0.26306942,\n",
       " 0.4100711,\n",
       " 0.00044464244,\n",
       " 0.36099094,\n",
       " 0.0012487045,\n",
       " 0.09397481,\n",
       " 0.28216955,\n",
       " 0.8700742,\n",
       " 0.7004547,\n",
       " 0.5058652,\n",
       " 0.17297909,\n",
       " 0.4133413,\n",
       " 0.0014194692,\n",
       " 0.70686316,\n",
       " 0.61832273,\n",
       " 0.0049589006,\n",
       " 0.12220405,\n",
       " 0.49820372,\n",
       " 0.9343795,\n",
       " 0.39364952,\n",
       " 0.4669253,\n",
       " 0.01680802,\n",
       " 0.9049725,\n",
       " 0.57298326,\n",
       " 0.76636523,\n",
       " 0.57619786,\n",
       " 0.76276296,\n",
       " 0.88869303,\n",
       " 0.42075646,\n",
       " 0.3386524,\n",
       " 0.7315983,\n",
       " 0.9478598,\n",
       " 0.62635124,\n",
       " 0.2825689,\n",
       " 0.8668771,\n",
       " 0.41613784,\n",
       " 0.45145723,\n",
       " 0.0010127742,\n",
       " 0.0009393078,\n",
       " 0.8601903,\n",
       " 0.674351,\n",
       " 0.71662664,\n",
       " 0.47042587,\n",
       " 0.22775549,\n",
       " 0.213066,\n",
       " 0.94231206,\n",
       " 0.9641003,\n",
       " 0.25411996,\n",
       " 0.04527566,\n",
       " 0.34839064,\n",
       " 0.03237303,\n",
       " 0.7685529,\n",
       " 0.08033299,\n",
       " 0.015904257,\n",
       " 0.8321358,\n",
       " 0.39821577,\n",
       " 0.9674241,\n",
       " 0.5752656,\n",
       " 0.117794536,\n",
       " 0.0071980697,\n",
       " 0.004827866,\n",
       " 0.089250594,\n",
       " 0.6344271,\n",
       " 0.8152986,\n",
       " 0.40759596,\n",
       " 0.96754676,\n",
       " 0.02720313,\n",
       " 0.0004949827,\n",
       " 0.5901521,\n",
       " 0.09309065,\n",
       " 0.00025629145,\n",
       " 0.10229534,\n",
       " 0.08578441,\n",
       " 0.0034036362,\n",
       " 0.016761096,\n",
       " 0.7212448,\n",
       " 0.5097621,\n",
       " 0.91908234,\n",
       " 0.53665936,\n",
       " 0.63109225,\n",
       " 0.23308723,\n",
       " 0.08127325,\n",
       " 0.69140035,\n",
       " 0.99809676,\n",
       " 0.0016964346,\n",
       " 0.0003338346,\n",
       " 0.59908855,\n",
       " 0.5038103,\n",
       " 0.93491054,\n",
       " 0.9702641,\n",
       " 0.3872325,\n",
       " 0.8776663,\n",
       " 0.0268817,\n",
       " 0.81238216,\n",
       " 0.8182816,\n",
       " 0.88182455,\n",
       " 0.28406635,\n",
       " 0.72011316,\n",
       " 0.10646162,\n",
       " 0.39090937,\n",
       " 0.5647072,\n",
       " 0.540412,\n",
       " 0.47562614,\n",
       " 0.7347373,\n",
       " 0.45405373,\n",
       " 0.012345539,\n",
       " 0.008916519,\n",
       " 0.012891952,\n",
       " 0.0017379862,\n",
       " 0.03092536,\n",
       " 0.58744335,\n",
       " 0.006734328,\n",
       " 0.903024,\n",
       " 0.9173127,\n",
       " 0.08193896,\n",
       " 0.007928395,\n",
       " 0.9635711,\n",
       " 0.0014537548,\n",
       " 0.7138326,\n",
       " 0.0797262,\n",
       " 0.6705463,\n",
       " 0.7495023,\n",
       " 0.70793515,\n",
       " 0.93272245,\n",
       " 0.6951139,\n",
       " 0.12299856,\n",
       " 0.38337082,\n",
       " 0.16430813,\n",
       " 0.68180776,\n",
       " 0.26594397,\n",
       " 0.49027836,\n",
       " 0.3372026,\n",
       " 0.9381133,\n",
       " 0.6933176,\n",
       " 0.02991177,\n",
       " 0.037476227,\n",
       " 0.77438426,\n",
       " 0.5631998,\n",
       " 0.10692787,\n",
       " 0.6280191,\n",
       " 0.16179144,\n",
       " 0.087247424,\n",
       " 0.3785729,\n",
       " 0.7510711,\n",
       " 0.0009887833,\n",
       " 0.97401977,\n",
       " 0.055883184,\n",
       " 0.0054797786,\n",
       " 0.5887078,\n",
       " 0.6495026,\n",
       " 0.2086385,\n",
       " 0.64331466,\n",
       " 0.52031964,\n",
       " 0.0015054933,\n",
       " 0.4656365,\n",
       " 0.3655162,\n",
       " 0.75052625,\n",
       " 0.4181095,\n",
       " 0.43299386,\n",
       " 0.28215203,\n",
       " 0.045608725,\n",
       " 0.21655637,\n",
       " 9.090558e-05,\n",
       " 0.702039,\n",
       " 0.007518918,\n",
       " 0.61660373,\n",
       " 0.7168665,\n",
       " 0.85099465,\n",
       " 0.8879724,\n",
       " 0.99255013,\n",
       " 0.48546803,\n",
       " 0.6586557,\n",
       " 0.82387364,\n",
       " 0.77717674,\n",
       " 0.82771564,\n",
       " 0.4356634,\n",
       " 0.6550683,\n",
       " 0.46727195,\n",
       " 0.00042583566,\n",
       " 0.21094136,\n",
       " 0.8402706,\n",
       " 0.26831907,\n",
       " 0.53637767,\n",
       " 0.19050618,\n",
       " 0.27637112,\n",
       " 0.9706325,\n",
       " 0.7002854,\n",
       " 0.10694845,\n",
       " 0.86669534,\n",
       " 0.7450244,\n",
       " 0.71238697,\n",
       " 0.0030414348,\n",
       " 0.4316869,\n",
       " 0.07292168,\n",
       " 0.6282281,\n",
       " 0.058734074,\n",
       " 0.59689647,\n",
       " 0.2618031,\n",
       " 0.38318616,\n",
       " 0.15071823,\n",
       " 0.06520264,\n",
       " 0.004880964,\n",
       " 0.39566448,\n",
       " 0.62394845,\n",
       " 0.51064545,\n",
       " 0.0005151881,\n",
       " 0.41409308,\n",
       " 0.76196146,\n",
       " 0.7242241,\n",
       " 0.2904886,\n",
       " 0.0013706035,\n",
       " 0.6377605,\n",
       " 0.3505762,\n",
       " 0.52451503,\n",
       " 0.1395819,\n",
       " 0.1412364,\n",
       " 0.45449674,\n",
       " 0.30705154,\n",
       " 0.07121055,\n",
       " 0.92499095,\n",
       " 0.7024,\n",
       " 0.18751192,\n",
       " 0.61371356,\n",
       " 0.3348096,\n",
       " 0.01836565,\n",
       " 0.1469139,\n",
       " 0.5743228,\n",
       " 0.5583966,\n",
       " 0.04113419,\n",
       " 0.5360368,\n",
       " 0.0007000887,\n",
       " 0.83326626,\n",
       " 0.45796433,\n",
       " 0.5473484,\n",
       " 0.9135841,\n",
       " 7.745113e-05,\n",
       " 0.7091583,\n",
       " 0.42036596,\n",
       " 0.012188206,\n",
       " 0.3694474,\n",
       " 0.8333514,\n",
       " 0.0023008196,\n",
       " 0.028305039,\n",
       " 0.4075844,\n",
       " 0.003983176,\n",
       " 0.08489597,\n",
       " 0.13985316,\n",
       " 0.26239023,\n",
       " 0.71259516,\n",
       " 6.037793e-05,\n",
       " 0.2660697,\n",
       " 0.75013995,\n",
       " 0.35791,\n",
       " 0.9023538,\n",
       " 0.14772925,\n",
       " 0.8598656,\n",
       " 0.73354477,\n",
       " 0.0026710974,\n",
       " 0.86743265,\n",
       " 0.047666755,\n",
       " 0.60778046,\n",
       " 0.8397639,\n",
       " 0.60598123,\n",
       " 0.03556222,\n",
       " 0.76475805,\n",
       " 0.49568552,\n",
       " 3.668356e-06,\n",
       " 0.66466784,\n",
       " 0.15270689,\n",
       " 0.01723793,\n",
       " 0.34373936,\n",
       " 0.53763187,\n",
       " 0.21796681,\n",
       " 0.026189381,\n",
       " 8.898066e-05,\n",
       " 0.59922695,\n",
       " 0.03648027,\n",
       " 0.44035012,\n",
       " 3.3572458e-06,\n",
       " 0.81073385,\n",
       " 0.52805257,\n",
       " 0.9544114,\n",
       " 0.66692084,\n",
       " 0.051783644,\n",
       " 0.01855673,\n",
       " 0.23409016,\n",
       " 0.46563447,\n",
       " 0.2547452,\n",
       " 0.39288276,\n",
       " 0.04921187,\n",
       " 0.27764654,\n",
       " 0.95189875,\n",
       " 0.008126773,\n",
       " 0.99069804,\n",
       " 0.00029053344,\n",
       " 0.14974149,\n",
       " 0.33113596,\n",
       " 0.17545071,\n",
       " 3.7730602e-05,\n",
       " 0.8899634,\n",
       " 0.0014305101,\n",
       " 0.667068,\n",
       " 0.44882953,\n",
       " 0.00040976313,\n",
       " 0.6249696,\n",
       " 0.99529284,\n",
       " 0.9318645,\n",
       " 0.6079691,\n",
       " 0.5026013,\n",
       " 0.42133737,\n",
       " 0.074492306,\n",
       " 0.37538338,\n",
       " 0.038528055,\n",
       " 0.02243617,\n",
       " 0.6763894,\n",
       " 0.63841707,\n",
       " 0.56331396,\n",
       " 0.883758,\n",
       " 0.13027763,\n",
       " 0.0024548993,\n",
       " 0.88075083,\n",
       " 0.56540436,\n",
       " 0.61537385,\n",
       " 0.8941775,\n",
       " 0.6674418,\n",
       " 0.001659703,\n",
       " 0.0015898386,\n",
       " 0.2491573,\n",
       " 0.54569274,\n",
       " 0.5444963,\n",
       " 0.0003268157,\n",
       " 0.9364189,\n",
       " 0.69237185,\n",
       " 0.43191028,\n",
       " 0.6443611,\n",
       " 0.033616714,\n",
       " 0.0012714154,\n",
       " 0.067639105,\n",
       " 0.0031488608,\n",
       " 0.6979954,\n",
       " ...]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test_predictions)[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3992967,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(label_test_input, test_predictions)\n",
    "plt.xlabel('True Values [MPG]')\n",
    "plt.ylabel('Predictions [MPG]')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.xlim([0,plt.xlim()[1]])\n",
    "plt.ylim([0,plt.ylim()[1]])\n",
    "_ = plt.plot([-100, 100], [-100, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class model_all(object):\n",
    "    def model_fit(self, model, n_batch_size=256, n_epochs=5):\n",
    "        num_factors=self.num_factors\n",
    "        model=self.model\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
